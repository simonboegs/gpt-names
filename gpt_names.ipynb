{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Character-level Language Model for Name Generation\n",
        "Hello, welcome to my first transformer, a character level language model that generates names. It took me ~1.5 months of off-and-on work to make it happen.\n",
        "\n",
        "At a high level, the model is tasked with predicting the next character in a name. Once it can do this, we can sample letters from the model one after the other and generate new names.\n",
        "\n",
        "The dataset consists of 32033 names. I got the idea for this and the dataset from Andrej Karpathy's youtube tutorials which I found helpful. However, I want to make clear that I did this BEFORE he released his \"GPT-style\" tutorial (in which he does a project similar to this one)!!\n",
        "\n",
        "Key takeways from the project\n",
        "- ML models are hard to debug. The whole thing can run perfectly (no runtime errors) and still be wrong in many places. Make sure to start with the simplest model and the simplest dataset and scale up from there to ensure the whole thing works properly.\n",
        "- ML models can be conceptually complicated while not requiring many lines of code. I tried to understand every part of the model before writing any code by writing some textbook-style explanations for myself. I took many breaks from the project (finals, winter break was happening) and constantly had to refer to my notes to remind myself of conceptual things and double check if my code was doing what it was supposed to. I would definitely recommend this.\n",
        "- Torch's tensor operations were uncomfortable to use at first but I started to get the hang of it. I tried hard to avoid \"for\" loops when debugging or doing anything in favor of tensor operations. \".view()\" is incredibly useful.\n",
        "- Torch's Cross Entropy Loss calculation is weird"
      ],
      "metadata": {
        "id": "8leHrXwvlhfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic imports, setting the device to use the gpu if possible."
      ],
      "metadata": {
        "id": "ftnBdbX0mBTn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cyy7tulip92F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0162d38e-5ee9-4359-dfa9-67e81bef76b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\") \n",
        "else:\n",
        "  device = \"cpu\"\n",
        "torch.cuda.get_device_name(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch Andrej Karpathy's names dataset."
      ],
      "metadata": {
        "id": "BCMlzv7rmKfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnejynNguHcj",
        "outputId": "a31fd6bc-58e9-4586-8bc1-edd0526d4dd3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-20 23:42:03--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-01-20 23:42:03 (8.57 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self attention layer implementations. I implemented a single-headed and multi-headed version, but only the multi-headed attention is used in the decoder.\n",
        "\n",
        "The attention layers were the hardest to get right. At times the attention mechanism was privy to the information of the following characters in the sequence, which resulted in a model that could achieve very low loss while not being able to generate good names."
      ],
      "metadata": {
        "id": "xTLn1TTZrg-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleHeadAttention(torch.nn.Module):\n",
        "  def __init__(self, model_dim, masked=False):\n",
        "    super().__init__()\n",
        "    self.model_dim = model_dim\n",
        "    self.mask = masked\n",
        "\n",
        "    # query, key, and value matrices. in the form of torch Linear layers\n",
        "    self.QW = torch.nn.Linear(model_dim, model_dim, bias=False)\n",
        "    self.KW = torch.nn.Linear(model_dim, model_dim, bias=False)\n",
        "    self.VW = torch.nn.Linear(model_dim, model_dim, bias=False)\n",
        "\n",
        "  def init_weights(self):\n",
        "    torch.nn.init.xavier_uniform_(self.QW.weight)\n",
        "    torch.nn.init.xavier_uniform_(self.KW.weight)\n",
        "    torch.nn.init.xavier_uniform_(self.VW.weight)\n",
        "\n",
        "  def forward(self, X):\n",
        "    # X has shape (batch size, seqence len, model dim)\n",
        "    Q = self.QW(X)\n",
        "    K = self.KW(X)\n",
        "    V = self.VW(X)\n",
        "    \n",
        "    # flip the last 2 dimensions \n",
        "    K_transpose = torch.transpose(K, 1, 2)\n",
        "\n",
        "    score = (Q @ K_transpose) / np.sqrt(self.model_dim)\n",
        "\n",
        "    if self.masked: \n",
        "      neg_inf = torch.full(size=score.size(), fill_value=-float(\"inf\")).to(device)\n",
        "      mask = torch.triu(neg_inf, diagonal=1).to(device)\n",
        "      score += mask\n",
        "\n",
        "    softmax = torch.nn.Softmax(dim=2)\n",
        "    score_softmax = softmax(score)\n",
        "\n",
        "    Z = score_softmax @ V\n",
        "    return Z\n",
        "\n",
        "class MultiHeadAttention(torch.nn.Module):\n",
        "  def __init__(self, model_dim, heads, masked=False):\n",
        "    super().__init__()\n",
        "    self.model_dim = model_dim\n",
        "    self.QW = torch.nn.Linear(model_dim, model_dim, bias=False)\n",
        "    self.KW = torch.nn.Linear(model_dim, model_dim, bias=False)\n",
        "    self.VW = torch.nn.Linear(model_dim, model_dim, bias=False)\n",
        "    self.proj = torch.nn.Linear(model_dim, model_dim, bias=False)\n",
        "    self.heads = heads \n",
        "    self.masked = masked\n",
        "\n",
        "  def init_weights(self):\n",
        "    torch.nn.init.xavier_uniform_(self.QW.weight)\n",
        "    torch.nn.init.xavier_uniform_(self.KW.weight)\n",
        "    torch.nn.init.xavier_uniform_(self.VW.weight)\n",
        "    torch.nn.init.xavier_uniform_(self.proj.weight)\n",
        "  \n",
        "  def forward(self, X, X_enc=None):\n",
        "    Q = self.QW(X)\n",
        "\n",
        "    if X_enc is not None:\n",
        "      K = self.KW(X_enc)\n",
        "      V = self.VW(X_enc)\n",
        "    else:\n",
        "      K = self.KW(X)\n",
        "      V = self.VW(X)\n",
        "\n",
        "    # partition and reshape matrices based on heads\n",
        "    # how does this work with masking?\n",
        "    partition_len = int(self.model_dim / self.heads)\n",
        "    batch_size = Q.size()[0]\n",
        "    seq_len = Q.size()[1]\n",
        "    # partitian last dimension into 2\n",
        "    # stick remaining dimensionality into 2nd dimension\n",
        "    # transpose so that 2nd dimension is heads\n",
        "    Q = Q.view(batch_size, -1, self.heads, partition_len).transpose(1,2)\n",
        "    K = K.view(batch_size, -1, self.heads, partition_len).transpose(1,2)\n",
        "    V = V.view(batch_size, -1, self.heads, partition_len).transpose(1,2)\n",
        "\n",
        "    # matmul will \"broadcast\" batch and head dimensions\n",
        "    score = Q @ torch.transpose(K, 2, 3) / np.sqrt(self.model_dim)\n",
        "    if self.masked: \n",
        "      neg_inf = torch.full(size=score.size(), fill_value=-float(\"inf\")).to(device)\n",
        "      mask = torch.triu(neg_inf, diagonal=1).to(device)\n",
        "      score += mask\n",
        "\n",
        "    softmax = torch.nn.Softmax(dim=3)\n",
        "    score_softmax = softmax(score)\n",
        "    \n",
        "    Z = score_softmax @ V\n",
        "\n",
        "    # undo partition\n",
        "    Z = Z.transpose(1, 2).reshape(batch_size, -1, self.model_dim) \n",
        "    # final matrix multiplication, \"projection\"\n",
        "    return self.proj(Z)\n",
        "\n",
        "    # residual connection is handled in sublayer class"
      ],
      "metadata": {
        "id": "YhRoqpL-rVuK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional embedding layer. It adjusts the input embeddings in a sequence to add positional information using a certain function."
      ],
      "metadata": {
        "id": "JpBNQKqNsdh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionEmbedding(torch.nn.Module): \n",
        "  def __init__(self, max_size=10000):\n",
        "    super().__init__()\n",
        "    self.max_size = max_size\n",
        "        \n",
        "  def forward(self, X):\n",
        "    seq_len = X.size(dim=1)\n",
        "    model_dim = X.size(dim=2)\n",
        "    # self.pos_embed = np.array(shape=(seq_len, model_dim))\n",
        "    pos_embed = torch.zeros(size=(seq_len, model_dim)).to(device)\n",
        "    for pos in range(seq_len):\n",
        "      for i in range(model_dim):\n",
        "        pos_embed[pos][i] = np.sin( pos / ( self.max_size**( 2*i / model_dim ) ) )\n",
        "    return X + pos_embed"
      ],
      "metadata": {
        "id": "s92Ju-TVfQ7O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we construct the datasets and dataloaders using torch."
      ],
      "metadata": {
        "id": "U6DlbbXjs6Qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "val_set_size = int(.1 * 32000)\n",
        "\n",
        "class Vocab():\n",
        "  def __init__(self, end_token=\".\", pad_token=\"#\"): \n",
        "    # end token and start token are the same.\n",
        "    self.end_token = end_token\n",
        "    self.pad_token = pad_token\n",
        "\n",
        "    words = open(\"names.txt\",\"r\").read().splitlines()\n",
        "    chars = sorted(list(set(\"\".join(words))))\n",
        "\n",
        "    self.end_token_idx = len(chars)\n",
        "    self.pad_token_idx = len(chars) + 1\n",
        "\n",
        "    # maps characters to indices\n",
        "    self.stoi = {s:i for i,s in enumerate(chars)}\n",
        "    self.stoi[end_token] = self.end_token_idx\n",
        "    self.stoi[pad_token] = self.pad_token_idx\n",
        "\n",
        "    # maps indices to characters\n",
        "    self.itos = {i:s for s,i in self.stoi.items()}\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.stoi) \n",
        "\n",
        "vocab = Vocab()\n",
        "\n",
        "class Names(torch.utils.data.Dataset):\n",
        "  def __init__(self, train=True):\n",
        "    self.words = open(\"names.txt\",\"r\").read().splitlines()\n",
        "    random.shuffle(self.words)\n",
        "    if train:\n",
        "      self.words = self.words[:-1*val_set_size]\n",
        "    else:\n",
        "      self.words = self.words[-1*val_set_size:]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.words)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    word = self.words[idx]\n",
        "    return [vocab.end_token_idx] + [vocab.stoi[i] for i in word] + [vocab.end_token_idx]\n",
        "\n",
        "dataset_tr = Names(train=True)\n",
        "dataset_val = Names(train=False)\n",
        "print(f\"train set len: {len(dataset_tr)}\")\n",
        "print(f\"val set len: {len(dataset_val)}\")\n",
        "\n",
        "# just pads all sequences in batch to same length. \n",
        "# future: put small w small, large w large to minimize padding\n",
        "def collate_fn(batch):\n",
        "  max_len = max([len(seq) for seq in batch])\n",
        "  for i in range(len(batch)):\n",
        "    batch[i] += [vocab.pad_token_idx] * (max_len - len(batch[i]))\n",
        "  \n",
        "  return torch.tensor(batch)\n",
        "\n",
        "dataloader_tr = torch.utils.data.DataLoader(\n",
        "    dataset_tr, \n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "  )\n",
        "dataloader_val = torch.utils.data.DataLoader(\n",
        "    dataset_val, \n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "  )"
      ],
      "metadata": {
        "id": "WPlELzZtuUFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b949ab5-1951-4830-b618-c55e05234a5c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set len: 28833\n",
            "val set len: 3200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder and its building blocks called \"sublayers.\""
      ],
      "metadata": {
        "id": "bUz1-uckvvJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT-style decoder only tranformer architecture\n",
        "\n",
        "class DecoderOnlySubLayer(torch.nn.Module):\n",
        "  def __init__(self, model_dim, vocab_size, num_heads):\n",
        "    super().__init__()\n",
        "    self.model_dim = model_dim\n",
        "    self.vocab_size = vocab_size\n",
        "\n",
        "\n",
        "    # masked self attention\n",
        "    self.attn = MultiHeadAttention(model_dim, num_heads, masked=True)\n",
        "    self.norm1 = torch.nn.LayerNorm(model_dim)\n",
        "\n",
        "    # feed forward\n",
        "    ff_dim = 4 * model_dim # read that this was good setting\n",
        "    self.ff1 = torch.nn.Linear(model_dim, ff_dim)\n",
        "    # can use either one\n",
        "    self.tanh = torch.nn.Tanh()\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.ff2 = torch.nn.Linear(ff_dim, model_dim)\n",
        "    self.norm2 = torch.nn.LayerNorm(model_dim)\n",
        "\n",
        "  def forward(self, X):\n",
        "    # X is shape (batch size, sequence length, model_dim)\n",
        "    # self attention\n",
        "    attn_out = self.attn(X)\n",
        "    attn_out_normed = self.norm1(attn_out + X)\n",
        "\n",
        "    # feed forward\n",
        "    ff1_preact = self.ff1(attn_out_normed)\n",
        "    ff1_out = self.tanh(ff1_preact)\n",
        "    ff2_out = self.ff2(ff1_out)\n",
        "    ff2_out_normed = self.norm2(ff2_out + attn_out_normed)\n",
        "    return ff2_out_normed\n",
        "  \n",
        "  # initialization could be slightly improved using Kaiming initialization intead of Xavier\n",
        "  def init_weights(self):\n",
        "    self.attn.init_weights()\n",
        "    torch.nn.init.xavier_uniform_(self.ff1.weight)\n",
        "    torch.nn.init.zeros_(self.ff1.bias)\n",
        "    torch.nn.init.xavier_uniform_(self.ff2.weight)\n",
        "    torch.nn.init.zeros_(self.ff2.bias)\n",
        "    torch.nn.init.ones_(self.norm1.weight)\n",
        "    torch.nn.init.zeros_(self.norm1.bias)\n",
        "    torch.nn.init.ones_(self.norm2.weight)\n",
        "    torch.nn.init.zeros_(self.norm2.bias)\n",
        "\n",
        "class DecoderOnly(torch.nn.Module):\n",
        "  def __init__(self, model_dim, vocab_size, num_sublayers, num_heads):\n",
        "    super().__init__()\n",
        "    # this layer projects one hot encoded vectors of length=vocab_size to embeddings of length=model_dim.\n",
        "    self.linear_embed = torch.nn.Linear(vocab_size, model_dim)\n",
        "    self.pos_encode = PositionEmbedding()\n",
        "    self.sublayers = torch.nn.ModuleList([DecoderOnlySubLayer(model_dim, vocab_size, num_heads) for _ in range(num_sublayers)])\n",
        "    self.linear_out = torch.nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X_embed = self.linear_embed(X)\n",
        "    X_pos_encoded = self.pos_encode(X_embed)\n",
        "\n",
        "    sublayer_out = X_pos_encoded\n",
        "    for sublayer in self.sublayers:\n",
        "      sublayer_out = sublayer(sublayer_out)\n",
        "\n",
        "    logits = self.linear_out(sublayer_out)\n",
        "    return logits\n",
        "\n",
        "  def init_weights(self):\n",
        "    torch.nn.init.xavier_uniform_(self.linear_embed.weight)\n",
        "    torch.nn.init.zeros_(self.linear_embed.bias)\n",
        "    [sublayer.init_weights() for sublayer in self.sublayers]\n",
        "    torch.nn.init.xavier_uniform_(self.linear_out.weight)\n",
        "    torch.nn.init.zeros_(self.linear_out.bias)\n"
      ],
      "metadata": {
        "id": "zwJXjSbriid6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model params\n",
        "model_dim = 32 \n",
        "num_sublayers = 4\n",
        "num_heads = 8\n",
        "\n",
        "# training params\n",
        "lr = .03\n",
        "epochs = 50\n",
        "\n",
        "model = DecoderOnly(model_dim, len(vocab), num_sublayers, num_heads).to(device)\n",
        "model.init_weights()\n",
        "\n",
        "CE_loss = torch.nn.CrossEntropyLoss(ignore_index=vocab.pad_token_idx, reduction=\"mean\").to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "  losses_running_tr = []\n",
        "  for batch_idx, batch in enumerate(dataloader_tr):\n",
        "    # wtf does this do again?\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # create one hot encodings from indices and chop off last character in each sequence (we can't predict past the last character)\n",
        "    \n",
        "    X = torch.nn.functional.one_hot(batch[:,:-1],num_classes=len(vocab)).float().to(device)\n",
        "\n",
        "    # chop off first character in each sequence (the targets provide the correct character to be predicted.)\n",
        "    Y = batch[:,1:].to(device)\n",
        "\n",
        "    logits = model(X)\n",
        "\n",
        "    # flatten everything for easy loss calculation (torch's CE loss implementation cannot handle such unflattened tensors)\n",
        "    # the actual loss is a mean of all loss values.\n",
        "    loss = CE_loss(logits.view(-1,len(vocab)), Y.view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses_running_tr.append(loss.item())\n",
        "\n",
        "  # ----------------------\n",
        "  # validation\n",
        "\n",
        "  losses_running_val = []\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(dataloader_val):\n",
        "      X = torch.nn.functional.one_hot(batch[:,:-1],num_classes=len(vocab)).float().to(device)\n",
        "      Y = batch[:,1:].to(device)\n",
        "\n",
        "      logits = model(X)\n",
        "\n",
        "      loss = CE_loss(logits.view(-1,len(vocab)), Y.view(-1))\n",
        "\n",
        "      losses_running_val.append(loss.item())\n",
        "\n",
        "  losses.append((np.array(losses_running_tr).mean(),np.array(losses_running_val).mean()))  \n",
        "  \n",
        "  print(f\"epoch {epoch} {losses[-1]}\")\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.legend((\"tr\",\"val\"))\n",
        "plt.title(\"loss over epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IT1vnwTZrLsb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "daf4f296-ade4-4cd6-ef43-7d91c8276e96"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 (2.5740370433240667, 2.428519649505615)\n",
            "epoch 1 (2.376777763641594, 2.3464225816726683)\n",
            "epoch 2 (2.3150112713519855, 2.299526195526123)\n",
            "epoch 3 (2.282283146999892, 2.282074251174927)\n",
            "epoch 4 (2.2598500119608946, 2.2607011508941652)\n",
            "epoch 5 (2.2428078492834933, 2.2371724462509155)\n",
            "epoch 6 (2.2276446866883406, 2.2380037450790407)\n",
            "epoch 7 (2.2156497147553775, 2.2281865072250366)\n",
            "epoch 8 (2.204743119935503, 2.223374948501587)\n",
            "epoch 9 (2.1945022521685074, 2.1873847389221193)\n",
            "epoch 10 (2.1854777373125707, 2.1992902517318726)\n",
            "epoch 11 (2.1773059785762543, 2.1858183002471923)\n",
            "epoch 12 (2.169878699034122, 2.167123007774353)\n",
            "epoch 13 (2.1628839816328163, 2.1612925052642824)\n",
            "epoch 14 (2.156178038294722, 2.150251703262329)\n",
            "epoch 15 (2.1500226341171436, 2.1561383056640624)\n",
            "epoch 16 (2.144694895543439, 2.1494831657409668)\n",
            "epoch 17 (2.1382485688922146, 2.1430498361587524)\n",
            "epoch 18 (2.1333945672422185, 2.1360157251358034)\n",
            "epoch 19 (2.1286525665524265, 2.131099810600281)\n",
            "epoch 20 (2.123892884032425, 2.120054988861084)\n",
            "epoch 21 (2.1186537877419043, 2.1304182028770446)\n",
            "epoch 22 (2.1143408421666554, 2.1389963674545287)\n",
            "epoch 23 (2.1098209601019544, 2.1143915271759033)\n",
            "epoch 24 (2.10601618892602, 2.103655045032501)\n",
            "epoch 25 (2.101751635185631, 2.1110088634490967)\n",
            "epoch 26 (2.096996283055409, 2.107467930316925)\n",
            "epoch 27 (2.0940054250662183, 2.101720538139343)\n",
            "epoch 28 (2.090011013585025, 2.096223604679108)\n",
            "epoch 29 (2.0866214758540997, 2.087390732765198)\n",
            "epoch 30 (2.0828649617087285, 2.09394832611084)\n",
            "epoch 31 (2.079672549886344, 2.087180552482605)\n",
            "epoch 32 (2.076104395141094, 2.080007050037384)\n",
            "epoch 33 (2.0727209421060566, 2.0898384141921995)\n",
            "epoch 34 (2.0693419436922094, 2.0830676460266115)\n",
            "epoch 35 (2.066679311433018, 2.0864744687080385)\n",
            "epoch 36 (2.06330083664135, 2.0646126317977904)\n",
            "epoch 37 (2.0604393714811744, 2.0623594903945923)\n",
            "epoch 38 (2.0573681859906654, 2.065574281215668)\n",
            "epoch 39 (2.0542041660676773, 2.054070544242859)\n",
            "epoch 40 (2.0517659398774613, 2.0621228075027465)\n",
            "epoch 41 (2.0481525371450013, 2.055637571811676)\n",
            "epoch 42 (2.045506594450669, 2.0589662098884585)\n",
            "epoch 43 (2.0431276956312936, 2.054117639064789)\n",
            "epoch 44 (2.040017942102944, 2.050901837348938)\n",
            "epoch 45 (2.0377546234300024, 2.048676173686981)\n",
            "epoch 46 (2.034493603621777, 2.0383567786216736)\n",
            "epoch 47 (2.032459080615752, 2.037162969112396)\n",
            "epoch 48 (2.0293691398827836, 2.045000367164612)\n",
            "epoch 49 (2.0266780184536444, 2.0375460958480835)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample from the model to generate a batch of names!\n",
        "- there are more complicated algorithms like beam search that might yield better results, I just used a simple greedy method here."
      ],
      "metadata": {
        "id": "24l80P2ezu5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generates batch of names by sampling from model\n",
        "max_name_len = 15\n",
        "\n",
        "softmax = torch.nn.Softmax(dim=2)\n",
        "indices = torch.tensor([vocab.stoi[\".\"]] * 64).view(64,1).to(device)\n",
        "X = torch.nn.functional.one_hot(indices, len(vocab)).to(device)\n",
        "with torch.no_grad():\n",
        "  for i in range(max_name_len):\n",
        "    X = torch.nn.functional.one_hot(indices, len(vocab)).float().to(device)\n",
        "\n",
        "    logits = model(X)\n",
        "    probs = softmax(logits)\n",
        "    \n",
        "    samples = torch.multinomial(probs[:,-1,:].view(64, -1), 1, replacement=True)\n",
        "    indices = torch.concat((indices, samples),dim=1)\n",
        "\n",
        "for i in range(indices.shape[0]):\n",
        "  s = \"\"\n",
        "  for j in range(1,indices.shape[1]):\n",
        "    char = vocab.itos[indices[i][j].item()]\n",
        "    if char == \".\":\n",
        "      break\n",
        "    s += char\n",
        "  print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAnQZn3NoGNy",
        "outputId": "6db379b6-b900-45ee-dd65-ee174223bbc1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaseri\n",
            "hanna\n",
            "zeve\n",
            "tyneli\n",
            "matcy\n",
            "durianza\n",
            "mikris\n",
            "lorani\n",
            "rhily\n",
            "taisem\n",
            "vingei\n",
            "anaya\n",
            "baryon\n",
            "chritlei\n",
            "khasima\n",
            "alizie\n",
            "ariyah\n",
            "schaft\n",
            "lealton\n",
            "graret\n",
            "deni#ion\n",
            "riyase\n",
            "xahael\n",
            "maravion\n",
            "jeravioh\n",
            "naahm\n",
            "adyya\n",
            "jarmanie\n",
            "sahyla\n",
            "rozlin\n",
            "ellyne\n",
            "kyleanie\n",
            "kinna\n",
            "cyour\n",
            "quanson\n",
            "chansopomus\n",
            "natana\n",
            "jordo\n",
            "keluber\n",
            "hira\n",
            "zohim\n",
            "bark\n",
            "lanna\n",
            "tayisa\n",
            "kessin\n",
            "yerina\n",
            "khreen\n",
            "losvie\n",
            "mckly\n",
            "sorei\n",
            "saninyah\n",
            "breley\n",
            "makenlie\n",
            "aviya\n",
            "haime\n",
            "kainon\n",
            "audra\n",
            "mariah\n",
            "jayavia\n",
            "anio\n",
            "won\n",
            "coub\n",
            "\n",
            "jerem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autocomplete any name!\n",
        "- make sure to put the start/end token \".\" at the beginning"
      ],
      "metadata": {
        "id": "cL3Nu7wQ0hpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \".emm\"\n",
        "\n",
        "softmax = torch.nn.Softmax(dim=2)\n",
        "seq = torch.tensor([vocab.stoi[i] for i in s]).to(device)\n",
        "with torch.no_grad():\n",
        "  while not (seq[-1] == vocab.end_token_idx and len(seq) > 1):\n",
        "    X = torch.nn.functional.one_hot(seq.view(1,-1),num_classes=len(vocab)).float().to(device)\n",
        "\n",
        "    logits = model(X)\n",
        "\n",
        "    probs = softmax(logits)[0,seq.size(dim=0)-1]\n",
        "\n",
        "    sample = torch.multinomial(probs, 1, replacement=True)\n",
        "\n",
        "    seq = torch.concat((seq, sample))\n",
        "\n",
        "  chars = [vocab.itos[i.item()] for i in seq]\n",
        "  print(\"\".join(chars[1:-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_72P37PORrK",
        "outputId": "9946cbd5-014d-43da-ae5d-0a913078e9f9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emmerie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ulOcfWz90VYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BGzyCh9UAlvR"
      }
    }
  ]
}